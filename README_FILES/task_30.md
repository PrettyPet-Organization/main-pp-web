# Задача №30: Базовые настройки devops в проекте.
## Цель:
Наметить вероятный путь развития devops в проекте. Добавить некоторые файлы, которые в дальнейшем будут дописываться.
## Описание:
Проект будет представлять из себя набор микросервисов, каждый из которых запускается в своем Docker-контейнере.
Сами контейнеры будут общаться друг с другом в Docker Network, создаваемой Docker Compose.

### 1. Как будет осуществляться взаимодействие микросервисов в проекте?

Ответ:

* микросервисы будут общаться в Docker Network через Kafka по протолку gRPC.
* Почему Kafka? -- Это брокер сообщений, позволяющий уменьшить связность сервисов и, тем самым, в будущем очень гибко настраивать их взаимодействие. А во-вторых, Kafka
хоть и считается достаточно сложной в освоении технологией, но по ней много информации и плагинов, позволяющих настроить
брокера под свои нужды.
* Почему gRPC? -- Вопрос спорный: под предполагаемое количество микросервисов вполне может подойти и REST, но
gRPC обеспечивает бОльшую скорость передачи информации, что важно при высокой нагрузке сервиса.

### 2. Как будет организована структура devops каждого микросервиса?

Ответ:

Каждый микросервис будет запускаться в своем Docker-контейнере с необходимым переменными окружения,
общение между сервисами будет осуществляться по каналам Docker Network.

Несмотря на принцип Database-per-service, для нашего проекта кажется целесообразным оставить одну общую
базу данных, общение с которой будет происходить через Kafka. Это устранит (по крайней мере на начальном этапе)
проблему синхронизации данных между БД, а race conditions и низкую скорость обработки запросов базой
можно устранять изменением окружения и настроек БД.

### 3. Как запустить контейнер микросервиса?

Ответ:

Отдельного микросервиса -- запуск docker-compose.yml из его репозитория.
Запуск всего сервиса -- запуск docker-compose.yml из репозитория main.

Наполнение compose-файла для каждого отдельного сервиса зависит от запросов разработки и тестирования.

### 4. Что положить в pipeline? Какой сценарий?

Ответ:

* Пайплайн (пока что без кода):

  * Для разработки (веток develop в репозиториях):

    1. По инструкции берем таску и оформляем её решение.

    2. Далее выполняется PR из ветки таски в develop соответствующего сервиса.

    3. PR запускает CI-сценарий (Github actions workflow), который в job клонирует текущую develop в runner и выполняет мердж с веткой таски (проверка на отсутствие конфликтов слияния).

    4. Далее выполняется запуск необходимых тестов (написанных заранее).

    5. Если все хорошо — PR одобрен. Ждем код-ревью и одобрения слияния.

  * Для продакшена (ветки PROM в репозитории main, я так понимаю):

    1. Для PR в develop репозитория main сценарий такой же, что и для develop репозиториев выше.

    2. Для слияния (git merge) develop с PROM выполняется запуск CD-сценарий.

    3. Github Actions workflow собирает docker-образы микросервисов и пушит их в какое-нибудь Registry (этап тестов пропускается, тк предполагается, что в develop лежит уже протестированный код).

    4. Далее workflow подключается к production-серверу по ssh.

    5. Производится подтягивание образов для docker compose из хранилища образов и запуск сети контейнеров рядом с работающей, если таковая имеется, с переключением балансировщика нагрузки со старой версии на новую (паттерн Blue-Green Deployment).

    6. Отправляется уведомление (куда угодно) об успешном деплое.

* Сценарий:

  * Бизнес-сценарий (что приложение делает с позиции клиента):

    Прописано в документации проекта в Notion/coda.

  * Системный сценарий (логика обработки запроса):

    Пример: авторизованный клиент переходит в личный кабинет по нажатию кнопки на сайте.

    1. Клиент отправляет запрос, который получает, обрабатывает и отправляет в нужный микросервис веб-сервер.

    2. Микросервис на Python верифицирует клиента и запрашивает у базы данных информацию для формирования страницы личного кабинета через Kafka.

    3. Kafka добавляет запрос в очередь сообщений и (когда доходит очередь) передаёт её в контейнер с базой данных.

    4. База данных возвращает информацию по данным клиента (также через Kafka) микросервису Python.

    5. Микросервис возвращает данные обратно Nginx. Nginx, в свою очередь, добавляет к ответу необходимые статические файлы и отправляет это
    клиенту.

### 4. Какие задачи будет выполнять репозиторий main?

Ответ:

  * Точка сбора всего приложения: именно из этого репозитория будет производится деплой.
  * Здесь будут лежать compose-файл для сборки всего проекта, настройки веб-сервера и Kafka.
  * Здесь будет лежать общая документация по проекту.