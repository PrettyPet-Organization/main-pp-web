### Основной DevOps репозиторий веб-платформы PrettyPet

### Какие задачи выполняет репозиторий main
* Точка сбора всего приложения: именно из этого репозитория будет производиться deploy.
* Здесь будут лежать compose-файл для сборки всего проекта, настройки веб-сервера и Kafka.
* Здесь будет лежать общая документация по проекту.

### Как будет осуществляться взаимодействие микросервисов в проекте
* микросервисы будут общаться в Docker Network через Kafka по протолку gRPC.
* Почему Kafka? -- Это брокер сообщений, позволяющий уменьшить связность сервисов и, тем самым, в будущем очень гибко настраивать их взаимодействие. А во-вторых, Kafka
  хоть и считается достаточно сложной в освоении технологией, но по ней много информации и плагинов, позволяющих настроить
  брокера под свои нужды.
* Почему gRPC? -- Вопрос спорный: под предполагаемое количество микросервисов вполне может подойти и REST, но
  gRPC обеспечивает бОльшую скорость передачи информации, что важно при высокой нагрузке сервиса.

### Как организована структура devops каждого микросервиса
Каждый микросервис будет запускаться в своем Docker-контейнере с необходимым переменными окружения,
общение между сервисами будет осуществляться по каналам Docker Network.

Несмотря на принцип Database-per-service, для нашего проекта кажется целесообразным оставить одну общую
базу данных, общение с которой будет происходить через Kafka. Это устранит (по крайней мере на начальном этапе)
проблему синхронизации данных между БД, а race conditions и низкую скорость обработки запросов базой
можно устранять изменением окружения и настроек БД.

### Как запустить контейнер микросервиса
Отдельного микросервиса -- запуск docker-compose.yml из его репозитория.
Запуск всего сервиса -- запуск docker-compose.yml из репозитория main.

Наполнение compose-файла для каждого отдельного сервиса зависит от запросов разработки и тестирования.

### Что положить в pipeline?
* Пайплайн (пока что без кода):

    * Для разработки (веток develop в репозиториях):

        1. По инструкции берем таску и оформляем её решение.

        2. Далее выполняется PR из ветки таски в develop соответствующего сервиса.

        3. PR запускает CI-сценарий (Github actions workflow), который в job клонирует текущую develop в runner и выполняет мердж с веткой таски (проверка на отсутствие конфликтов слияния).

        4. Далее выполняется запуск необходимых тестов (написанных заранее).

        5. Если все хорошо — PR одобрен. Ждем код-ревью и одобрения слияния.

    * Для продакшена (ветки PROM в репозитории main, я так понимаю):

        1. Для PR в develop репозитория main сценарий такой же, что и для develop репозиториев выше.

        2. Для слияния (git merge) develop с PROM выполняется запуск CD-сценарий.

        3. Github Actions workflow собирает docker-образы микросервисов и пушит их в какое-нибудь Registry (этап тестов пропускается, тк предполагается, что в develop лежит уже протестированный код).

        4. Далее workflow подключается к production-серверу по ssh.

        5. Производится подтягивание образов для docker compose из хранилища образов и запуск сети контейнеров рядом с работающей, если таковая имеется, с переключением балансировщика нагрузки со старой версии на новую (паттерн Blue-Green Deployment).

        6. Отправляется уведомление (куда угодно) об успешном деплое.

* Сценарий:

    * Бизнес-сценарий (что приложение делает с позиции клиента):

      Прописано в документации проекта в Notion/coda.

    * Системный сценарий (логика обработки запроса):

      Пример: авторизованный клиент переходит в личный кабинет по нажатию кнопки на сайте.

        1. Клиент отправляет запрос, который получает, обрабатывает и отправляет в нужный микросервис веб-сервер.

        2. Микросервис на Python верифицирует клиента и запрашивает у базы данных информацию для формирования страницы личного кабинета через Kafka.

        3. Kafka добавляет запрос в очередь сообщений и (когда доходит очередь) передаёт её в контейнер с базой данных.

        4. База данных возвращает информацию по данным клиента (также через Kafka) микросервису Python.

        5. Микросервис возвращает данные обратно Nginx. Nginx, в свою очередь, добавляет к ответу необходимые статические файлы и отправляет это
           клиенту.